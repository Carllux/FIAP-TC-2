{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8ab657",
   "metadata": {},
   "source": [
    "## üîÑ Ajuste do Diret√≥rio de Trabalho\n",
    "\n",
    "Antes de carregar ou manipular arquivos, √© importante garantir que estamos no diret√≥rio correto do projeto.  \n",
    "O c√≥digo abaixo verifica se o notebook est√° sendo executado a partir da pasta `notebooks`. Se for o caso, ele sobe um n√≠vel na hierarquia de diret√≥rios para garantir que o diret√≥rio de trabalho seja a raiz do projeto.\n",
    "\n",
    "Isso √© √∫til para manter caminhos relativos consistentes ao acessar dados, scripts ou outros recursos do projeto.\n",
    "\n",
    "üìå **Resumo do que o c√≥digo faz:**\n",
    "- Verifica se o diret√≥rio atual termina com `notebooks`.\n",
    "- Se sim, volta uma pasta (para a raiz do projeto).\n",
    "- Exibe o novo diret√≥rio de trabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb73e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diret√≥rio de Trabalho Atual: c:\\Users\\Carlo\\Desktop\\Portfolio\\postech-challenge-ibov\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verifica se o diret√≥rio de trabalho atual termina com 'notebooks'\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    # Se sim, sobe um n√≠vel de diret√≥rio para a pasta raiz do projeto\n",
    "    os.chdir('..')\n",
    "\n",
    "# Imprime o diret√≥rio de trabalho para confirmar que a mudan√ßa foi feita\n",
    "print(f\"Diret√≥rio de Trabalho Atual: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677da460",
   "metadata": {},
   "source": [
    "## üì¶ Carregamento das Bibliotecas para a Fase 3: Modelagem Preditiva\n",
    "\n",
    "Nesta etapa, carregamos todas as bibliotecas necess√°rias para realizar o treinamento, valida√ß√£o e interpreta√ß√£o de modelos de Machine Learning aplicados √† previs√£o da tend√™ncia do Ibovespa.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Principais Componentes Importados:\n",
    "\n",
    "#### üìä Manipula√ß√£o de Dados\n",
    "- `pandas`, `numpy`: Estrutura√ß√£o e transforma√ß√£o de dados tabulares e num√©ricos.\n",
    "- `duckdb`: Consulta e carregamento eficiente da base persistida na fase anterior.\n",
    "\n",
    "#### ‚öôÔ∏è Modelagem e Avalia√ß√£o\n",
    "- `lightgbm`: Framework de gradient boosting eficiente, usado para modelagem supervisionada.\n",
    "- `sklearn.model_selection.train_test_split`: Divis√£o da base de forma temporal para simular previs√£o realista.\n",
    "- `sklearn.metrics`: Avalia√ß√£o com m√©tricas como `accuracy`, `ROC AUC`, `confusion_matrix`.\n",
    "\n",
    "#### üß† Interpreta√ß√£o do Modelo\n",
    "- `shap`: Framework de interpretabilidade para entender a import√¢ncia das features no modelo treinado.\n",
    "\n",
    "#### üìà Visualiza√ß√£o\n",
    "- `matplotlib`, `seaborn`: Cria√ß√£o de gr√°ficos e an√°lise visual dos resultados.\n",
    "\n",
    "#### üõ†Ô∏è Configura√ß√£o do Projeto\n",
    "- `src.config`: Importa o caminho e demais par√¢metros definidos nas fases anteriores.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Todas as bibliotecas e depend√™ncias da **Fase 3 - Modelagem** foram carregadas com sucesso e est√£o prontas para uso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8cf2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas para a Fase 3 carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit # Usaremos para a divis√£o temporal\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importa nossas configura√ß√µes de projeto\n",
    "import src.config as config\n",
    "\n",
    "# Helpers do Notebook\n",
    "from IPython.display import display\n",
    "\n",
    "# Configura√ß√µes de estilo\n",
    "sns.set_theme(style='whitegrid', palette='viridis')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Bibliotecas para a Fase 3 carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a086f8",
   "metadata": {},
   "source": [
    "## üß± Carregamento dos Dados para Modelagem\n",
    "\n",
    "Nesta etapa, buscamos no banco de dados DuckDB a tabela `features_completas`, que cont√©m todas as vari√°veis criadas e tratadas na **Fase 2** do projeto. Esses dados s√£o a base para o treinamento dos modelos de Machine Learning.\n",
    "\n",
    "---\n",
    "\n",
    "### üì• Etapas Realizadas:\n",
    "\n",
    "1. **Conex√£o ao Banco DuckDB**\n",
    "   - Utilizamos o caminho salvo no m√≥dulo `config`.\n",
    "\n",
    "2. **Leitura da Tabela `features_completas`**\n",
    "   - A tabela cont√©m os dados finais ap√≥s a engenharia de atributos, com a vari√°vel `alvo` (target) j√° definida.\n",
    "\n",
    "3. **Convers√£o da Coluna `data`**\n",
    "   - A coluna `data` √© convertida para o tipo `datetime` e definida como √≠ndice do DataFrame.\n",
    "   - Essa configura√ß√£o √© fundamental para **garantir uma divis√£o temporal correta** entre treino e teste, evitando vazamento de dados.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Ao final desta c√©lula, temos o DataFrame `df_model` carregado, indexado por data e pronto para os pr√≥ximos passos de prepara√ß√£o e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80aa981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados da tabela 'features_completas' de: C:\\Users\\Carlo\\Desktop\\Portfolio\\postech-challenge-ibov\\data\\mercados.duckdb\n",
      "\n",
      "‚úÖ Dados para modelagem carregados com sucesso!\n",
      "Estrutura do DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2975 entries, 2014-02-05 to 2025-07-03\n",
      "Data columns (total 83 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   close_petroleo_brent             2975 non-null   float64\n",
      " 1   close_petrobras                  2975 non-null   float64\n",
      " 2   close_dolar                      2975 non-null   float64\n",
      " 3   close_ibovespa                   2975 non-null   float64\n",
      " 4   close_sp500                      2975 non-null   float64\n",
      " 5   high_petroleo_brent              2975 non-null   float64\n",
      " 6   high_petrobras                   2975 non-null   float64\n",
      " 7   high_dolar                       2975 non-null   float64\n",
      " 8   high_ibovespa                    2975 non-null   float64\n",
      " 9   high_sp500                       2975 non-null   float64\n",
      " 10  low_petroleo_brent               2975 non-null   float64\n",
      " 11  low_petrobras                    2975 non-null   float64\n",
      " 12  low_dolar                        2975 non-null   float64\n",
      " 13  low_ibovespa                     2975 non-null   float64\n",
      " 14  low_sp500                        2975 non-null   float64\n",
      " 15  open_petroleo_brent              2975 non-null   float64\n",
      " 16  open_petrobras                   2975 non-null   float64\n",
      " 17  open_dolar                       2975 non-null   float64\n",
      " 18  open_ibovespa                    2975 non-null   float64\n",
      " 19  open_sp500                       2975 non-null   float64\n",
      " 20  semana_do_mes                    2975 non-null   int32  \n",
      " 21  alvo                             2975 non-null   int32  \n",
      " 22  petroleo_brent_ret_acum_2d       2975 non-null   float64\n",
      " 23  petroleo_brent_ret_acum_5d       2975 non-null   float64\n",
      " 24  petroleo_brent_ret_acum_10d      2975 non-null   float64\n",
      " 25  petroleo_brent_ret_acum_21d      2975 non-null   float64\n",
      " 26  petrobras_ret_acum_2d            2975 non-null   float64\n",
      " 27  petrobras_ret_acum_5d            2975 non-null   float64\n",
      " 28  petrobras_ret_acum_10d           2975 non-null   float64\n",
      " 29  petrobras_ret_acum_21d           2975 non-null   float64\n",
      " 30  dolar_ret_acum_2d                2975 non-null   float64\n",
      " 31  dolar_ret_acum_5d                2975 non-null   float64\n",
      " 32  dolar_ret_acum_10d               2975 non-null   float64\n",
      " 33  dolar_ret_acum_21d               2975 non-null   float64\n",
      " 34  ibovespa_ret_acum_2d             2975 non-null   float64\n",
      " 35  ibovespa_ret_acum_5d             2975 non-null   float64\n",
      " 36  ibovespa_ret_acum_10d            2975 non-null   float64\n",
      " 37  ibovespa_ret_acum_21d            2975 non-null   float64\n",
      " 38  sp500_ret_acum_2d                2975 non-null   float64\n",
      " 39  sp500_ret_acum_5d                2975 non-null   float64\n",
      " 40  sp500_ret_acum_10d               2975 non-null   float64\n",
      " 41  sp500_ret_acum_21d               2975 non-null   float64\n",
      " 42  petroleo_brent_ret_diario        2975 non-null   float64\n",
      " 43  petrobras_ret_diario             2975 non-null   float64\n",
      " 44  dolar_ret_diario                 2975 non-null   float64\n",
      " 45  ibovespa_ret_diario              2975 non-null   float64\n",
      " 46  sp500_ret_diario                 2975 non-null   float64\n",
      " 47  petroleo_brent_ret_diario_lag_1  2975 non-null   float64\n",
      " 48  petrobras_ret_diario_lag_1       2975 non-null   float64\n",
      " 49  dolar_ret_diario_lag_1           2975 non-null   float64\n",
      " 50  ibovespa_ret_diario_lag_1        2975 non-null   float64\n",
      " 51  sp500_ret_diario_lag_1           2975 non-null   float64\n",
      " 52  petroleo_brent_ret_diario_lag_2  2975 non-null   float64\n",
      " 53  petrobras_ret_diario_lag_2       2975 non-null   float64\n",
      " 54  dolar_ret_diario_lag_2           2975 non-null   float64\n",
      " 55  ibovespa_ret_diario_lag_2        2975 non-null   float64\n",
      " 56  sp500_ret_diario_lag_2           2975 non-null   float64\n",
      " 57  petroleo_brent_ret_diario_lag_3  2975 non-null   float64\n",
      " 58  petrobras_ret_diario_lag_3       2975 non-null   float64\n",
      " 59  dolar_ret_diario_lag_3           2975 non-null   float64\n",
      " 60  ibovespa_ret_diario_lag_3        2975 non-null   float64\n",
      " 61  sp500_ret_diario_lag_3           2975 non-null   float64\n",
      " 62  petroleo_brent_ret_diario_lag_5  2975 non-null   float64\n",
      " 63  petrobras_ret_diario_lag_5       2975 non-null   float64\n",
      " 64  dolar_ret_diario_lag_5           2975 non-null   float64\n",
      " 65  ibovespa_ret_diario_lag_5        2975 non-null   float64\n",
      " 66  sp500_ret_diario_lag_5           2975 non-null   float64\n",
      " 67  gap_open_close_ibov              2975 non-null   float64\n",
      " 68  candle_body_ibov                 2975 non-null   float64\n",
      " 69  candle_range_ibov                2975 non-null   float64\n",
      " 70  ret_sp500_ontem                  2975 non-null   float64\n",
      " 71  ret_dolar_ontem                  2975 non-null   float64\n",
      " 72  BBL_5_2.0                        2975 non-null   float64\n",
      " 73  BBM_5_2.0                        2975 non-null   float64\n",
      " 74  BBU_5_2.0                        2975 non-null   float64\n",
      " 75  BBB_5_2.0                        2975 non-null   float64\n",
      " 76  BBP_5_2.0                        2975 non-null   float64\n",
      " 77  spread_petro_ibov                2975 non-null   float64\n",
      " 78  ret_dolar_1d                     2975 non-null   float64\n",
      " 79  ret_ibov_1d                      2975 non-null   float64\n",
      " 80  ret_diff_dolar_ibov              2975 non-null   float64\n",
      " 81  dia_da_semana                    2975 non-null   int32  \n",
      " 82  mes                              2975 non-null   int32  \n",
      "dtypes: float64(79), int32(4)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Carregando dados da tabela 'features_completas' de: {config.DB_PATH}\")\n",
    "\n",
    "try:\n",
    "    con = duckdb.connect(database=str(config.DB_PATH), read_only=True)\n",
    "    # MUITO IMPORTANTE: Selecionar da nova tabela com todas as features\n",
    "    df_model = con.execute(\"SELECT * FROM features_completas\").fetchdf()\n",
    "    con.close()\n",
    "\n",
    "    # Configura a coluna 'data' como o √≠ndice para facilitar a divis√£o temporal\n",
    "    df_model['data'] = pd.to_datetime(df_model['data'])\n",
    "    df_model.set_index('data', inplace=True)\n",
    "\n",
    "    print(\"\\n‚úÖ Dados para modelagem carregados com sucesso!\")\n",
    "    print(\"Estrutura do DataFrame:\")\n",
    "    df_model.info()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ocorreu um erro ao carregar os dados: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b417766",
   "metadata": {},
   "source": [
    "## üéØ Cria√ß√£o da Vari√°vel Alvo Multiclasse\n",
    "\n",
    "Para refinar o problema e permitir abordagens mais sofisticadas de modelagem, transformamos o alvo bin√°rio em uma **vari√°vel multiclasse com 3 categorias**, baseada na magnitude do retorno do dia seguinte do Ibovespa.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ L√≥gica Utilizada\n",
    "\n",
    "- **Classe 1 ‚Äì Alta Significativa**: Retorno > +0.5%\n",
    "- **Classe -1 ‚Äì Baixa Significativa**: Retorno < -0.5%\n",
    "- **Classe 0 ‚Äì Neutro**: Varia√ß√£o entre -0.5% e +0.5%\n",
    "\n",
    "Essa abordagem permite que o modelo diferencie entre movimentos significativos de mercado e ru√≠dos de varia√ß√£o di√°ria, tornando a previs√£o mais realista para aplica√ß√µes pr√°ticas como aloca√ß√£o de risco e decis√µes de trading.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Resultado\n",
    "\n",
    "A distribui√ß√£o das classes no conjunto de dados foi verificada, garantindo equil√≠brio e viabilidade para modelagem multiclasse. A √∫ltima linha (que teria alvo indefinido) foi removida para manter a integridade do dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2b8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Refinando o Problema: Cria√ß√£o do Alvo Multiclasse ---\n",
      "\n",
      "Distribui√ß√£o do nosso novo alvo multiclasse (em %):\n",
      "alvo_multiclasse\n",
      "-1    29.58%\n",
      " 0    36.64%\n",
      " 1    33.78%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Exibindo as √∫ltimas linhas com o novo alvo para valida√ß√£o manual:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "data",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "close_ibovespa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alvo_multiclasse",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "7004a627-3e64-43cb-ac1a-82a9006c0ef8",
       "rows": [
        [
         "2025-06-20 00:00:00",
         "137116.0",
         "0"
        ],
        [
         "2025-06-23 00:00:00",
         "136551.0",
         "0"
        ],
        [
         "2025-06-24 00:00:00",
         "137165.0",
         "-1"
        ],
        [
         "2025-06-25 00:00:00",
         "135767.0",
         "1"
        ],
        [
         "2025-06-26 00:00:00",
         "137114.0",
         "0"
        ],
        [
         "2025-06-27 00:00:00",
         "136866.0",
         "1"
        ],
        [
         "2025-06-30 00:00:00",
         "138855.0",
         "0"
        ],
        [
         "2025-07-01 00:00:00",
         "139549.0",
         "0"
        ],
        [
         "2025-07-02 00:00:00",
         "139051.0",
         "1"
        ],
        [
         "2025-07-03 00:00:00",
         "140928.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_ibovespa</th>\n",
       "      <th>alvo_multiclasse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-20</th>\n",
       "      <td>137116.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23</th>\n",
       "      <td>136551.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-24</th>\n",
       "      <td>137165.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-25</th>\n",
       "      <td>135767.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-26</th>\n",
       "      <td>137114.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-27</th>\n",
       "      <td>136866.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>138855.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>139549.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02</th>\n",
       "      <td>139051.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03</th>\n",
       "      <td>140928.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            close_ibovespa  alvo_multiclasse\n",
       "data                                        \n",
       "2025-06-20        137116.0                 0\n",
       "2025-06-23        136551.0                 0\n",
       "2025-06-24        137165.0                -1\n",
       "2025-06-25        135767.0                 1\n",
       "2025-06-26        137114.0                 0\n",
       "2025-06-27        136866.0                 1\n",
       "2025-06-30        138855.0                 0\n",
       "2025-07-01        139549.0                 0\n",
       "2025-07-02        139051.0                 1\n",
       "2025-07-03        140928.0                 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# O DataFrame 'df_model' foi carregado e tem a data como √≠ndice.\n",
    "\n",
    "print(\"--- Refinando o Problema: Cria√ß√£o do Alvo Multiclasse ---\")\n",
    "\n",
    "# 1. Definimos o nosso threshold de signific√¢ncia.\n",
    "# Um movimento de 0.5% (0.005) √© um bom ponto de partida.\n",
    "# Podemos ajustar este valor mais tarde se necess√°rio.\n",
    "threshold = 0.005\n",
    "\n",
    "# 2. Calculamos o retorno do dia seguinte para o Ibovespa\n",
    "retorno_futuro = df_model['close_ibovespa'].pct_change().shift(-1)\n",
    "\n",
    "# 3. Criamos a nova coluna 'alvo_multiclasse' com a l√≥gica de 3 classes\n",
    "# Usamos np.where aninhado, que funciona como um \"SE/SEN√ÉOSE/SEN√ÉO\"\n",
    "df_model['alvo_multiclasse'] = np.where(\n",
    "    retorno_futuro > threshold,      # Condi√ß√£o 1: Se o retorno futuro for > 0.5%\n",
    "    1,                               # Ent√£o, a classe √© 1 (Alta Significativa)\n",
    "    np.where(\n",
    "        retorno_futuro < -threshold, # Condi√ß√£o 2: Se o retorno futuro for < -0.5%\n",
    "        -1,                          # Ent√£o, a classe √© -1 (Baixa Significativa)\n",
    "        0                            # Caso contr√°rio, a classe √© 0 (Neutra)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4. Removemos o √∫ltimo dia, que ter√° um NaN no alvo\n",
    "df_model.dropna(subset=['alvo_multiclasse'], inplace=True)\n",
    "\n",
    "# --- Verifica√ß√£o ---\n",
    "print(\"\\nDistribui√ß√£o do nosso novo alvo multiclasse (em %):\")\n",
    "# Usamos value_counts para ver quantas amostras temos de cada classe\n",
    "print(df_model['alvo_multiclasse'].value_counts(normalize=True).sort_index().map('{:.2%}'.format))\n",
    "\n",
    "print(\"\\nExibindo as √∫ltimas linhas com o novo alvo para valida√ß√£o manual:\")\n",
    "display(df_model[['close_ibovespa', 'alvo_multiclasse']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da676136",
   "metadata": {},
   "source": [
    "## üì¶ Prepara√ß√£o dos Dados para o Modelo Multiclasse\n",
    "\n",
    "Agora que j√° temos nossa vari√°vel alvo multiclasse (`alvo_multiclasse`), preparamos os dados para a modelagem com tr√™s etapas fundamentais:\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ 1. Separa√ß√£o entre Features (X) e Alvo (y)\n",
    "\n",
    "- **X**: Todas as colunas do `df_model`, exceto `alvo_multiclasse` (nosso novo alvo) e `alvo` (alvo antigo bin√°rio, se ainda existir).\n",
    "- **y**: Apenas a coluna `alvo_multiclasse`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚è≥ 2. Divis√£o Temporal: Treino vs. Teste\n",
    "\n",
    "- Utilizamos **os √∫ltimos 6 meses como conjunto de teste**, mantendo a ordem temporal dos dados (fundamental para s√©ries temporais financeiras).\n",
    "- O restante do hist√≥rico √© usado para treino do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 3. Verifica√ß√£o da Distribui√ß√£o das Classes\n",
    "\n",
    "- Avaliamos a propor√ß√£o de cada classe (-1, 0, 1) tanto no treino quanto no teste.\n",
    "- Isso nos ajuda a identificar poss√≠veis desequil√≠brios entre os conjuntos que possam afetar a performance do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "Com isso, garantimos que os dados est√£o corretamente estruturados para prosseguir com a modelagem multiclasse do Ibovespa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfba37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparando Dados Finais para Modelo Multiclasse ---\n",
      "\n",
      "Separa√ß√£o X/y conclu√≠da.\n",
      "Shape de X (features): (2975, 82)\n",
      "Shape de y (alvo): (2975,)\n",
      "\n",
      "Data de corte para o conjunto de teste: 2025-01-03\n",
      "\n",
      "--- Tamanho dos Conjuntos ---\n",
      "Conjunto de Treino: 2846 amostras\n",
      "Conjunto de Teste: 129 amostras\n",
      "\n",
      "Distribui√ß√£o do alvo no conjunto de Treino:\n",
      "alvo_multiclasse\n",
      "-1    29.94%\n",
      " 0    36.05%\n",
      " 1    34.01%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribui√ß√£o do alvo no conjunto de Teste:\n",
      "alvo_multiclasse\n",
      "-1    21.71%\n",
      " 0    49.61%\n",
      " 1    28.68%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# O 'df_model' j√° cont√©m a coluna 'alvo_multiclasse' que criamos.\n",
    "\n",
    "print(\"--- Preparando Dados Finais para Modelo Multiclasse ---\")\n",
    "\n",
    "# 1. Separa√ß√£o de Features (X) e Alvo (y)\n",
    "# X s√£o todas as colunas, exceto nosso novo alvo. \n",
    "# Usamos errors='ignore' para n√£o dar erro se a coluna 'alvo' antiga j√° foi removida.\n",
    "X = df_model.drop(columns=['alvo_multiclasse', 'alvo'], errors='ignore') \n",
    "\n",
    "# y √© apenas a nossa nova coluna alvo multiclasse.\n",
    "y = df_model['alvo_multiclasse']\n",
    "\n",
    "print(\"\\nSepara√ß√£o X/y conclu√≠da.\")\n",
    "print(\"Shape de X (features):\", X.shape)\n",
    "print(\"Shape de y (alvo):\", y.shape)\n",
    "\n",
    "# 2. Divis√£o Temporal em Treino e Teste\n",
    "# Mantemos a mesma l√≥gica: √∫ltimos 6 meses para teste.\n",
    "ponto_de_corte = X.index.max() - pd.DateOffset(months=6)\n",
    "\n",
    "print(f\"\\nData de corte para o conjunto de teste: {ponto_de_corte.date()}\")\n",
    "\n",
    "X_treino = X[X.index < ponto_de_corte]\n",
    "X_teste = X[X.index >= ponto_de_corte]\n",
    "\n",
    "y_treino = y.loc[X_treino.index]\n",
    "y_teste = y.loc[X_teste.index]\n",
    "\n",
    "print(\"\\n--- Tamanho dos Conjuntos ---\")\n",
    "print(f\"Conjunto de Treino: {len(X_treino)} amostras\")\n",
    "print(f\"Conjunto de Teste: {len(X_teste)} amostras\")\n",
    "\n",
    "# 3. Verifica√ß√£o da distribui√ß√£o do alvo nos dois conjuntos\n",
    "print(\"\\nDistribui√ß√£o do alvo no conjunto de Treino:\")\n",
    "print(y_treino.value_counts(normalize=True).sort_index().map('{:.2%}'.format))\n",
    "\n",
    "print(\"\\nDistribui√ß√£o do alvo no conjunto de Teste:\")\n",
    "print(y_teste.value_counts(normalize=True).sort_index().map('{:.2%}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2e82c",
   "metadata": {},
   "source": [
    "## üîß Otimiza√ß√£o de Hiperpar√¢metros com Optuna (Modelo Multiclasse)\n",
    "\n",
    "Nesta etapa, usamos a biblioteca **Optuna** para encontrar a melhor combina√ß√£o de hiperpar√¢metros para o modelo **LightGBM Multiclasse**, maximizando a m√©trica **AUC (One-vs-Rest)** em uma valida√ß√£o cruzada temporal.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Estrat√©gia Utilizada\n",
    "\n",
    "- **Valida√ß√£o Cruzada Temporal (TimeSeriesSplit)**: Utilizamos 5 dobras (splits) respeitando a ordem temporal dos dados, fundamental em s√©ries temporais.\n",
    "- **Fun√ß√£o Objetivo**: Para cada combina√ß√£o de par√¢metros, treinamos o modelo em m√∫ltiplos folds e retornamos a m√©dia do AUC.\n",
    "- **Espa√ßo de Busca**: Foram testados hiperpar√¢metros como n√∫mero de √°rvores (`n_estimators`), taxa de aprendizado (`learning_rate`), profundidade m√°xima (`max_depth`), n√∫mero de folhas (`num_leaves`) e regulariza√ß√µes L1/L2 (`reg_alpha`, `reg_lambda`).\n",
    "- **Modelo**: `LightGBMClassifier` com `objective='multiclass'` e `metric='multi_logloss'`.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Resultados\n",
    "\n",
    "- **Total de Combina√ß√µes Avaliadas**: 100\n",
    "- **Melhor Score (AUC M√©dio)**: Apresentado ao final da execu√ß√£o\n",
    "- **Melhores Hiperpar√¢metros**: S√£o armazenados em `best_params`\n",
    "\n",
    "---\n",
    "\n",
    "Com essa otimiza√ß√£o, aumentamos significativamente as chances do nosso modelo multiclasse alcan√ßar maior performance e generaliza√ß√£o no conjunto de teste real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 19:10:20,592] A new study created in memory with name: no-name-30a03f7b-8f4f-4cc9-9cbc-a91e1376e320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Otimiza√ß√£o de Hiperpar√¢metros com Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 19:10:29,424] Trial 0 finished with value: 0.5212060135271501 and parameters: {'n_estimators': 202, 'learning_rate': 0.29357502678256947, 'num_leaves': 250, 'max_depth': 8, 'reg_alpha': 0.4180995409037658, 'reg_lambda': 0.5432989244088593}. Best is trial 0 with value: 0.5212060135271501.\n",
      "[I 2025-07-06 19:10:44,702] Trial 1 finished with value: 0.5181096097073736 and parameters: {'n_estimators': 882, 'learning_rate': 0.2805789885508433, 'num_leaves': 255, 'max_depth': 8, 'reg_alpha': 0.2351600152544845, 'reg_lambda': 0.5581450814876018}. Best is trial 0 with value: 0.5212060135271501.\n",
      "[I 2025-07-06 19:11:14,658] Trial 2 finished with value: 0.5215192465048546 and parameters: {'n_estimators': 383, 'learning_rate': 0.06926025441511806, 'num_leaves': 129, 'max_depth': 10, 'reg_alpha': 0.8937184587552391, 'reg_lambda': 0.3391058954527302}. Best is trial 2 with value: 0.5215192465048546.\n",
      "[I 2025-07-06 19:11:31,947] Trial 3 finished with value: 0.5180419418747786 and parameters: {'n_estimators': 316, 'learning_rate': 0.12330931431151744, 'num_leaves': 112, 'max_depth': 5, 'reg_alpha': 0.6863196437526897, 'reg_lambda': 0.3104803689614124}. Best is trial 2 with value: 0.5215192465048546.\n"
     ]
    }
   ],
   "source": [
    "# Usaremos os dados X_treino, y_treino que j√° separamos.\n",
    "\n",
    "print(\"--- Iniciando Otimiza√ß√£o de Hiperpar√¢metros com Optuna ---\")\n",
    "\n",
    "# 1. Definir a estrat√©gia de Valida√ß√£o Cruzada para S√©ries Temporais\n",
    "# Usaremos 5 \"cortes\" (splits) nos nossos dados de treino.\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 2. Definir a fun√ß√£o \"objetivo\" que o Optuna ir√° maximizar\n",
    "def objective(trial):\n",
    "    # Definimos o espa√ßo de busca para os hiperpar√¢metros do LightGBM\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': 3, # Temos 3 classes: 1 (Alta), -1 (Baixa), 0 (Neutro)\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0), # L1 regularization\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0), # L2 regularization\n",
    "        'random_state': 42,\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1 # Usa todos os cores da CPU\n",
    "    }\n",
    "    \n",
    "    # Lista para guardar os scores de cada dobra da valida√ß√£o cruzada\n",
    "    scores = []\n",
    "    \n",
    "    # Loop de Valida√ß√£o Cruzada\n",
    "    for train_index, val_index in tscv.split(X_treino):\n",
    "        X_train_fold, X_val_fold = X_treino.iloc[train_index], X_treino.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_treino.iloc[train_index], y_treino.iloc[val_index]\n",
    "        \n",
    "        # Treina o modelo\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Faz previs√µes de probabilidade e calcula o score AUC\n",
    "        y_proba = model.predict_proba(X_val_fold)\n",
    "        score = roc_auc_score(y_val_fold, y_proba, multi_class='ovr')\n",
    "        scores.append(score)\n",
    "        \n",
    "    # Retorna a m√©dia dos scores. O Optuna tentar√° maximizar este valor.\n",
    "    return np.mean(scores)\n",
    "\n",
    "# 3. Criar e executar o estudo\n",
    "# 'direction=\"maximize\"' porque queremos o maior AUC poss√≠vel\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# Vamos testar 100 combina√ß√µes diferentes de par√¢metros\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 4. Exibir os resultados\n",
    "print(\"\\n--- Otimiza√ß√£o Conclu√≠da ---\")\n",
    "print(\"N√∫mero de trials conclu√≠dos: \", len(study.trials))\n",
    "print(\"Melhor score AUC na valida√ß√£o cruzada: \", study.best_value)\n",
    "\n",
    "print(\"\\nMelhores hiperpar√¢metros encontrados:\")\n",
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
